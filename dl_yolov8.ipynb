{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.213, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in speech-bubbles-detection-9 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 330880/330880 [01:18<00:00, 4215.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to speech-bubbles-detection-9 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9144/9144 [00:03<00:00, 2831.95it/s] \n"
     ]
    }
   ],
   "source": [
    "# !pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"FUFofgREYhzkCMsWXuFQ\")\n",
    "project = rf.workspace(\"ibn-zohr-university\").project(\"speech-bubbles-detection\")\n",
    "dataset = project.version(9).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.213 ðŸš€ Python-3.11.5 torch-2.1.1+cu121 CUDA:0 (NVIDIA RTX A6000, 45623MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/media/hpc-lavasa/Data/21_Reiyonna/speech-bubbles-detection-9/data.yaml, epochs=150, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012018 parameters, 3012002 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /media/hpc-lavasa/Data/21_Reiyonna/speech-bubbles-detection-9/tr\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /media/hpc-lavasa/Data/21_Reiyonna/speech-bubbles-detection-9/vali\u001b[0m\n",
      "Plotting labels to runs/detect/train7/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train7\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/150      2.49G     0.8802      1.611      1.017        197        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.764      0.621      0.671        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/150      2.46G       0.79     0.8894     0.9725        152        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.657      0.732      0.731      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/150      2.52G     0.7734      0.783     0.9722        182        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.721      0.732      0.737      0.557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/150      2.51G     0.7672     0.7126     0.9783        161        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.798      0.754      0.814      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/150      2.45G     0.7522       0.66     0.9714        165        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.831      0.735      0.829      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/150      2.57G     0.7405     0.6318     0.9695        163        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.701      0.792      0.785      0.594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/150      2.47G     0.7341     0.6049     0.9676        102        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.795      0.833      0.853      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/150      2.47G     0.7297     0.5823     0.9662        161        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.794      0.769      0.833      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/150       2.5G     0.7244     0.5632     0.9656        150        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.757       0.74      0.773      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/150      2.45G     0.7219     0.5502     0.9637        138        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503       0.79      0.788        0.8      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/150      2.47G     0.7119     0.5282     0.9585        158        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.779      0.816      0.839      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/150      2.48G     0.7115     0.5213     0.9573        177        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.848      0.824      0.867      0.673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/150       2.5G     0.7038     0.5267     0.9565        174        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.843      0.797      0.853      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/150      2.45G     0.6997     0.5059     0.9542        140        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.841      0.817       0.85      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/150      2.46G     0.6955     0.4969     0.9526        129        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.863      0.804      0.864      0.668\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/150      2.55G     0.6846     0.4839     0.9487        149        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.861       0.82      0.876      0.684\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/150      2.57G      0.685     0.4864     0.9511        160        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.778      0.803      0.818      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/150      2.41G     0.6743      0.467      0.947        170        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503       0.88      0.805      0.865      0.677\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/150       2.5G     0.6779     0.4707     0.9469        115        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.863      0.808      0.864      0.676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/150      2.49G     0.6697     0.4555     0.9435        184        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.857      0.825       0.88      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/150      2.45G     0.6686     0.4485     0.9432        142        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.846      0.814      0.858      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/150       2.5G     0.6642     0.4531     0.9437        169        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.825      0.837      0.871      0.685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/150      2.51G     0.6596     0.4391     0.9393        149        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.843      0.844      0.879      0.691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/150       2.5G     0.6546     0.4319      0.939        131        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.859      0.822      0.861      0.675\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/150      2.45G     0.6545     0.4323       0.94        213        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.821      0.832      0.866      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/150      2.48G     0.6498     0.4262      0.938        155        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.859      0.823      0.866      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/150      2.54G     0.6478     0.4234     0.9352        154        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.882      0.803      0.875      0.685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/150      2.48G      0.642     0.4149     0.9319        114        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.837      0.822      0.858      0.676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/150      2.57G     0.6404     0.4137     0.9311        152        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.841      0.812      0.849      0.669\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/150      2.45G     0.6359     0.4107     0.9296        154        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.888      0.815      0.869       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/150      2.46G     0.6293     0.3981     0.9273        161        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.858       0.83      0.878      0.692\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/150      2.47G     0.6287     0.4001     0.9287        152        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.838      0.851       0.87      0.684\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/150      2.39G     0.6272     0.3976     0.9288        150        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.872      0.837       0.88      0.687\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/150      2.46G     0.6229     0.3945     0.9277        120        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.849      0.826      0.859      0.676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/150      2.46G     0.6185     0.3905      0.925        172        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503       0.89      0.825      0.868      0.684\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/150      2.52G     0.6093     0.3807     0.9194        150        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.883      0.823      0.872      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/150      2.58G     0.6112     0.3827     0.9227        143        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.877       0.84      0.872      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/150      2.39G      0.612     0.3858     0.9248        144        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.878      0.823      0.866      0.676\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/150       2.5G     0.6016     0.3767     0.9187        133        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.843      0.857      0.867      0.688\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/150      2.57G      0.603     0.3765     0.9191        164        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.875      0.817      0.865      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/150      2.48G     0.6006     0.3733     0.9166        145        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.859      0.827      0.861      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/150       2.5G     0.5929      0.368     0.9149        145        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        376       2503      0.863       0.84      0.873       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/150      2.11G     0.5891     0.3628     0.9128        166        640:  ^C\n",
      "     43/150      2.11G     0.5891     0.3628     0.9128        166        640:  \n",
      "Traceback (most recent call last):\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/bin/yolo\", line 8, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/cfg/__init__.py\", line 445, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/engine/model.py\", line 338, in train\n",
      "    self.trainer.train()\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/engine/trainer.py\", line 190, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/engine/trainer.py\", line 337, in _do_train\n",
      "    self.loss, self.loss_items = self.model(batch)\n",
      "                                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  Exception in thread  Thread-3 (_pin_memory_loop):\n",
      "  Traceback (most recent call last):\n",
      "    File \"/home/hpc-lavasa/anaconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/nn/tasks.py\", line 41, in forward\n",
      "        return self.loss(x, *args, **kwargs)\n",
      " self.run()\n",
      "  File \"/home/hpc-lavasa/anaconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/nn/tasks.py\", line 212, in loss\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
      "return self.criterion(preds, batch)    \n",
      " do_one_step()\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
      "          ^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/utils/loss.py\", line 188, in __call__\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^_, target_bboxes, target_scores, fg_mask, _ = self.assigner(^^\n",
      "^ ^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^  ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ \n",
      "   File \"/home/hpc-lavasa/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "                   ^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^return self._call_impl(*args, **kwargs)^\n",
      "^ ^^^^^^^^^^^^^ ^ ^ ^ ^^ ^ \n",
      "   File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/torch/multiprocessing/reductions.py\", line 355, in rebuild_storage_fd\n",
      "   ^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      " fd = df.detach()\n",
      "         ^^ ^^ ^ ^ ^ ^ ^  ^^ \n",
      "   File \"/home/hpc-lavasa/anaconda3/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      " with _resource_sharer.get_connection(self._id) as conn:\n",
      "          ^ ^ ^ ^ ^^  ^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/utils/tal.py\", line 115, in forward\n",
      "    mask_pos, align_metric, overlaps = self.get_pos_mask(pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points,\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/utils/tal.py\", line 136, in get_pos_mask\n",
      "    align_metric, overlaps = self.get_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/hpc-lavasa/Data/21_Reiyonna/Towards-Realtime-MOT/mot-tracker/lib/python3.11/site-packages/ultralytics/utils/tal.py\", line 158, in get_box_metrics\n",
      "    pd_boxes = pd_bboxes.unsqueeze(1).expand(-1, self.n_max_boxes, -1, -1)[mask_gt]\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hpc-lavasa/anaconda3/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hpc-lavasa/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 501, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hpc-lavasa/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 629, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# !pip install ultralytics\n",
    "!yolo train model=yolov8n.pt data=/media/hpc-lavasa/Data/21_Reiyonna/speech-bubbles-detection-9/data.yaml epochs=150 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"/media/hpc-lavasa/Data/21_Reiyonna/model/stage_1/runs/detect/train/weights/best.pt\")\n",
    "predictions = model(\"/media/hpc-lavasa/Data/21_Reiyonna/model/stage_1/speech-bubbles-detection-9/test/images/-76-_jpg.rf.8a67899305974b1efae44f4d754fa984.jpg\", save_txt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_file = predictions[0].save_dir\n",
    "image_folder = '/media/hpc-lavasa/Data/21_Reiyonna/model/stage_1/speech-bubbles-detection-9/test/images/-76-_jpg.rf.8a67899305974b1efae44f4d754fa984.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = image_folder.split('/')[-1].split('.jpg')[0]\n",
    "predictions_file+='/labels/{}.txt'.format(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   YOLO Coordinates  \\\n",
      "0   [((0.282446, 0.249125, 0.262773, 0.214892), 0)]   \n",
      "1   [((0.138334, 0.139739, 0.156755, 0.160715), 0)]   \n",
      "2    [((0.167245, 0.688745, 0.210165, 0.24447), 0)]   \n",
      "3    [((0.26469, 0.849302, 0.154862, 0.204983), 0)]   \n",
      "4   [((0.735031, 0.535895, 0.203066, 0.197065), 0)]   \n",
      "5   [((0.176682, 0.928586, 0.130691, 0.140859), 0)]   \n",
      "6   [((0.291442, 0.535635, 0.243418, 0.232214), 0)]   \n",
      "7   [((0.702508, 0.188169, 0.225516, 0.217851), 0)]   \n",
      "8    [((0.846284, 0.14775, 0.113445, 0.169743), 0)]   \n",
      "9   [((0.855036, 0.473605, 0.147279, 0.168716), 0)]   \n",
      "10   [((0.704707, 0.188758, 0.231704, 0.22195), 1)]   \n",
      "11  [((0.734824, 0.536085, 0.204662, 0.203115), 1)]   \n",
      "\n",
      "                                       Extracted Text  \n",
      "0   PER TOOl CH, AND On THAT Hill CvER There, WHen...  \n",
      "1       InTh Sluiner TFe HORSETAILS' SLPER YumAY TOOl  \n",
      "2   ALCNG WI SORIN TCO! HE KNOWS LOT OF STUFF, So ...  \n",
      "3                                         #soRRy, EN,  \n",
      "4       Wen SumeR Coves; Let's TALK MORE Abolt STARSI  \n",
      "5                                              SoNen;  \n",
      "6   Next Time, Let'S Bring MASTER Sokei WIth Ls? WIth  \n",
      "7   THERE'S PLLva TRee OvER THERE AND It Has RED F...  \n",
      "8                                 HEy, Did YCL Knowi?  \n",
      "9                                   By THE WAY, KLkEI  \n",
      "10  THeRE'$ PLla TRee CVER THERE AvD it Has Red FL...  \n",
      "11      Wen SumeR coves; Let's TALK MORE Abolt STARSI  \n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_text_from_yolo_coordinates(image_path, yolo_coordinates):\n",
    "    image = Image.open(image_path)\n",
    "    reader = easyocr.Reader(['en'])\n",
    "\n",
    "    for (x, y, width, height), label in yolo_coordinates:\n",
    "        left = int(x * image.width - width * image.width / 2)\n",
    "        top = int(y * image.height - height * image.height / 2)\n",
    "        right = int(x * image.width + width * image.width / 2)\n",
    "        bottom = int(y * image.height + height * image.height / 2)\n",
    "\n",
    "        region = image.crop((left, top, right, bottom))\n",
    "        result = reader.readtext(np.array(region), detail=0)\n",
    "        combined_text = \" \".join(result)\n",
    "\n",
    "        return combined_text  # Modified to return the extracted text\n",
    "\n",
    "\n",
    "# Read predictions from file\n",
    "with open(predictions_file, 'r') as file:\n",
    "    predictions = file.read()\n",
    "\n",
    "# Create a list to store data\n",
    "data = []\n",
    "\n",
    "# Extract text from YOLO coordinates and store in the data list\n",
    "for prediction in predictions.split('\\n'):\n",
    "    if prediction:\n",
    "        items = prediction.split()\n",
    "        label = items[0]\n",
    "        coordinates = tuple(map(float, items[1:]))\n",
    "        yolo_coordinates = [(coordinates, label)]\n",
    "        extracted_text = extract_text_from_yolo_coordinates(image_folder, yolo_coordinates)\n",
    "        data.append({'YOLO Coordinates': yolo_coordinates, 'Extracted Text': extracted_text})\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YOLO Coordinates</th>\n",
       "      <th>Extracted Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[((0.282446, 0.249125, 0.262773, 0.214892), 0)]</td>\n",
       "      <td>PER TOOl CH, AND On THAT Hill CvER There, WHen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[((0.138334, 0.139739, 0.156755, 0.160715), 0)]</td>\n",
       "      <td>InTh Sluiner TFe HORSETAILS' SLPER YumAY TOOl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[((0.167245, 0.688745, 0.210165, 0.24447), 0)]</td>\n",
       "      <td>ALCNG WI SORIN TCO! HE KNOWS LOT OF STUFF, So ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[((0.26469, 0.849302, 0.154862, 0.204983), 0)]</td>\n",
       "      <td>#soRRy, EN,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[((0.735031, 0.535895, 0.203066, 0.197065), 0)]</td>\n",
       "      <td>Wen SumeR Coves; Let's TALK MORE Abolt STARSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[((0.176682, 0.928586, 0.130691, 0.140859), 0)]</td>\n",
       "      <td>SoNen;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[((0.291442, 0.535635, 0.243418, 0.232214), 0)]</td>\n",
       "      <td>Next Time, Let'S Bring MASTER Sokei WIth Ls? WIth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[((0.702508, 0.188169, 0.225516, 0.217851), 0)]</td>\n",
       "      <td>THERE'S PLLva TRee OvER THERE AND It Has RED F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[((0.846284, 0.14775, 0.113445, 0.169743), 0)]</td>\n",
       "      <td>HEy, Did YCL Knowi?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[((0.855036, 0.473605, 0.147279, 0.168716), 0)]</td>\n",
       "      <td>By THE WAY, KLkEI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[((0.704707, 0.188758, 0.231704, 0.22195), 1)]</td>\n",
       "      <td>THeRE'$ PLla TRee CVER THERE AvD it Has Red FL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[((0.734824, 0.536085, 0.204662, 0.203115), 1)]</td>\n",
       "      <td>Wen SumeR coves; Let's TALK MORE Abolt STARSI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   YOLO Coordinates  \\\n",
       "0   [((0.282446, 0.249125, 0.262773, 0.214892), 0)]   \n",
       "1   [((0.138334, 0.139739, 0.156755, 0.160715), 0)]   \n",
       "2    [((0.167245, 0.688745, 0.210165, 0.24447), 0)]   \n",
       "3    [((0.26469, 0.849302, 0.154862, 0.204983), 0)]   \n",
       "4   [((0.735031, 0.535895, 0.203066, 0.197065), 0)]   \n",
       "5   [((0.176682, 0.928586, 0.130691, 0.140859), 0)]   \n",
       "6   [((0.291442, 0.535635, 0.243418, 0.232214), 0)]   \n",
       "7   [((0.702508, 0.188169, 0.225516, 0.217851), 0)]   \n",
       "8    [((0.846284, 0.14775, 0.113445, 0.169743), 0)]   \n",
       "9   [((0.855036, 0.473605, 0.147279, 0.168716), 0)]   \n",
       "10   [((0.704707, 0.188758, 0.231704, 0.22195), 1)]   \n",
       "11  [((0.734824, 0.536085, 0.204662, 0.203115), 1)]   \n",
       "\n",
       "                                       Extracted Text  \n",
       "0   PER TOOl CH, AND On THAT Hill CvER There, WHen...  \n",
       "1       InTh Sluiner TFe HORSETAILS' SLPER YumAY TOOl  \n",
       "2   ALCNG WI SORIN TCO! HE KNOWS LOT OF STUFF, So ...  \n",
       "3                                         #soRRy, EN,  \n",
       "4       Wen SumeR Coves; Let's TALK MORE Abolt STARSI  \n",
       "5                                              SoNen;  \n",
       "6   Next Time, Let'S Bring MASTER Sokei WIth Ls? WIth  \n",
       "7   THERE'S PLLva TRee OvER THERE AND It Has RED F...  \n",
       "8                                 HEy, Did YCL Knowi?  \n",
       "9                                   By THE WAY, KLkEI  \n",
       "10  THeRE'$ PLla TRee CVER THERE AvD it Has Red FL...  \n",
       "11      Wen SumeR coves; Let's TALK MORE Abolt STARSI  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mot-tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
